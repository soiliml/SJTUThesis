%# -*- coding: utf-8-unix -*-
%%==================================================
%% conclusion.tex for SJTUThesis
%% Encoding: UTF-8
%%==================================================

\begin{summary}
本论文主要研究目标是面相语音识别的结构化语言模型的研究。

在第一个研究工作中为了使得结构化语言模型的不同结构之间能够得到适合的充分的训练，文本首先考虑研究语言模型的自适应算法为后文工作做好铺垫。
本文的第一个研究工作得出：在语言模型中引入稳定算子beta进行初始学习率的自适应能够很大幅度忽略初始学习率对结果的影响；
同时，稳定算子能够较大幅度提升语言模型的收敛速度，有效减少不必要的训练时间；
在多种LSTM语言模型引入稳定算子的算法中，每个隐层的参数分别拥有自己独立的稳定算子会使结果更优。稳定算子的引入对于普通语言模型和多任务语言模型来看在语言模型的性能上没有明显区别，并不像实验前预期的那样或许能智能调整不同任务的学习速度从而提升最后的训练结果，
根据分析发现，这是因为多任务模型中为不同的任务分配权重已经可以达到不同任务学习速度不同的要求。
另一方面，在参数量合理、没有超出训练数据的收敛极限的情况下，越深的网络，引入稳定算子的结果越好。引入稳定算子的同时，在训练过程中对其加入L2正则优化会略微提升语言模型的性能，提升幅度大概1%，使稳定算子收敛在一个比较小的值。今后的工作中，会围绕稳定算子如何优化以达到提升性能的目的做下一步研究。

在本文最重要的面向意淫识别的结构化语言模型的研究工作中，我们提出了一个具有单向标注模型的多视图LSTM语言系统，该模型生成了只包含前文信息的词同步辅助信息特征。
这个辅助功能与单词序列结合起来，以训练一个多视图角的LSTM语言模型。
对该模型的五种不同的训练方法进行了测试，
并将其中最好的一个方法用于大规模数据集的语音识别重打分测试中。
在我们的模型与相关研究(n-gram语言模型，多任务语言模型，多视图语言模型，加前后文信息的斯坦福标注信息，多任务组合模型，多视角语言模型)的对比实验中，在英文PTB，英语Fisher和中文短信数据上，PPL,WER和SER作为评价标准。
我们所提出的模型显示了所有的字级功能的显著改进，包括POS、NER和chunking on WER和SER。
特别是针对英国费雪的POS特性，我们提出的模型不仅在PPL上给了gian($ 4.0\% $)，而且与基线(LSTM语言模型)相比，在ASR任务中也显示了显著的次错误率和句子错误率的减少(相对$ 4.0\% $和$ 2.0\% $)。
最重要的是，与传统标注模型(Stanford tool)所生成的多视角相比，我们的模型显示了在语音识别从打分任务中，提升了WER和SER分别为$ 4.4\% $和$ 2.2\% $。
对于多任、多视角和联合训练等相关模型，我们的模型都有不同程度的提升。

接着考虑如何用小参数在短时间内训练出高效的模型。
我们将深度学习中的教师-学生结构引入到语言模型中。

\end{summary}
